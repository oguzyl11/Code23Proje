import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate

# ==========================================
# ğŸ”‘ API KEY AYARI
# ==========================================
if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = "AIzaSyDKqVM_cGh3ceLzd4V-t58QhgodRnZZ4Yc"

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="FÄ±rat Ãœni Mevzuat AsistanÄ± (Pro)", layout="wide", page_icon="ğŸ“")
st.title("ğŸ“ FÄ±rat Ãœniversitesi Mevzuat AsistanÄ± (Ã‡oklu Kaynak)")

# --- SIDEBAR ---
with st.sidebar:
    st.header("ğŸ“‚ DokÃ¼man YÃ¶netimi")
    uploaded_files = st.file_uploader(
        "PDF DosyalarÄ±nÄ± YÃ¼kle",
        type="pdf",
        accept_multiple_files=True
    )

    st.divider()
    st.header("âš™ï¸ Parametreler")
    search_type = st.radio("Arama AlgoritmasÄ±", ["MMR (Ã‡eÅŸitlilik)", "Similarity (Benzerlik)"])
    chunk_size = st.slider("ParÃ§a Boyutu (Chunk Size)", 500, 2000, 1000)
    k_value = st.slider("Kaynak SayÄ±sÄ± (k)", 2, 10, 5)

    if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
        st.session_state.clear()
        st.rerun()


# --- FONKSÄ°YONLAR ---
def process_pdfs(files, chunk_s):
    all_docs = []
    if not os.path.exists("temp_files"):
        os.makedirs("temp_files")

    status_bar = st.progress(0)

    for i, file in enumerate(files):
        safe_name = os.path.basename(file.name)
        file_path = os.path.join("temp_files", safe_name)

        with open(file_path, "wb") as f:
            f.write(file.getbuffer())

        loader = PyPDFLoader(file_path)
        pages = loader.load()

        # Her sayfaya kaynak etiketi basÄ±yoruz
        for page in pages:
            page.metadata["source"] = safe_name

        splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_s, chunk_overlap=200)
        docs = splitter.split_documents(pages)
        all_docs.extend(docs)

        # Ä°lerleme Ã§ubuÄŸunu gÃ¼ncelle
        status_bar.progress((i + 1) / len(files))

    status_bar.empty()
    return all_docs


def get_vectorstore(docs):
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    db = Chroma.from_documents(docs, embeddings)
    return db


# --- UYGULAMA AKIÅI ---
if uploaded_files:
    if "db" not in st.session_state:
        with st.spinner("DokÃ¼manlar analiz ediliyor ve vektÃ¶r veritabanÄ± oluÅŸturuluyor..."):
            try:
                docs = process_pdfs(uploaded_files, chunk_size)
                st.session_state.db = get_vectorstore(docs)
                st.success(f"âœ… HazÄ±r! Toplam {len(uploaded_files)} dosya ve {len(docs)} bilgi parÃ§asÄ± iÅŸlendi.")
            except Exception as e:
                st.error(f"Hata oluÅŸtu: {e}")

    # Soru AlanÄ±
    st.markdown("---")
    question = st.text_input("Sorunuzu yazÄ±n:",
                             placeholder="Ã–rn: Lisans yÃ¶netmeliÄŸi ile yÃ¼ksek lisans danÄ±ÅŸmanlÄ±ÄŸÄ± arasÄ±ndaki farklar neler?")

    if question and "db" in st.session_state:
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)

        prompt_template = """
        Sen uzman bir akademik asistansÄ±n. Birden fazla kaynaÄŸÄ± tarayarak cevap veriyorsun.

        GÃ–REVLER:
        1. Soruyu aÅŸaÄŸÄ±daki baÄŸlama gÃ¶re cevapla.
        2. CevabÄ±n iÃ§inde hangi bilginin hangi dosyadan geldiÄŸini belirtmeye Ã§alÄ±ÅŸ (Ã–rn: "YÃ¶netmelik X'e gÃ¶re...").
        3. CevabÄ± madde madde ve anlaÅŸÄ±lÄ±r ÅŸekilde dÃ¼zenle.

        BaÄŸlam: {context}
        Soru: {question}

        Cevap:
        """
        PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

        if search_type == "MMR (Ã‡eÅŸitlilik)":
            retriever = st.session_state.db.as_retriever(search_type="mmr", search_kwargs={"k": k_value, "fetch_k": 20})
        else:
            retriever = st.session_state.db.as_retriever(search_kwargs={"k": k_value})

        qa_chain = RetrievalQA.from_chain_type(
            llm,
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )

        with st.spinner("Yapay zeka kaynaklarÄ± tarÄ±yor..."):
            res = qa_chain.invoke({"query": question})

            st.markdown("### ğŸ¤– Asistan CevabÄ±")
            st.write(res["result"])

            st.markdown("---")
            st.subheader("ğŸ“š KullanÄ±lan Kaynaklar")

            for i, doc in enumerate(res["source_documents"]):
                source_name = doc.metadata.get("source", "Bilinmiyor")
                page_num = doc.metadata.get("page", 0) + 1

                # FarklÄ± dosyalarÄ± farklÄ± renklerle gÃ¶stermek iÃ§in basit bir ikon mantÄ±ÄŸÄ±
                icon = "ğŸ“„" if "1747" in source_name else "ğŸ“‘"

                with st.expander(f"{icon} Kaynak {i + 1}: {source_name} (Sayfa {page_num})"):
                    st.info(doc.page_content)

elif not uploaded_files:
    st.info("ğŸ‘‹ BaÅŸlamak iÃ§in lÃ¼tfen sol menÃ¼den PDF dosyalarÄ±nÄ±zÄ± yÃ¼kleyin.")