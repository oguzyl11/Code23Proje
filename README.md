# ğŸ“„ FÄ±rat Ãœniversitesi Mevzuat AsistanÄ± (RAG Projesi - 1. Hafta)

Bu proje, **Tek KaynaklÄ± RAG (Retrieval-Augmented Generation)** mimarisini kullanarak, kullanÄ±cÄ±larÄ±n yÃ¼klediÄŸi PDF dokÃ¼manlarÄ± (Ã¶zellikle mevzuat metinleri) ile sohbet etmesini saÄŸlayan bir yapay zeka asistanÄ±dÄ±r.

**Ders/GÃ¶rev:** 1. Hafta â€” Tek KaynaklÄ± RAG Kurulumu

## ğŸš€ Projenin AmacÄ±
KullanÄ±cÄ± tarafÄ±ndan yÃ¼klenen uzun ve karmaÅŸÄ±k PDF dosyalarÄ±nÄ± analiz etmek, kullanÄ±cÄ±nÄ±n sorularÄ±na belgeye dayalÄ±, kaynak gÃ¶stererek ve halÃ¼sinasyon (uydurma) yapmadan cevap vermek.

## âœ¨ Ã–zellikler

* **PDF Ä°ÅŸleme:** YÃ¼klenen PDF dosyasÄ±nÄ± belirlenen karakter limitlerine (Chunk Size) gÃ¶re parÃ§alara ayÄ±rÄ±r.
* **Semantik Arama:** Sorulan soruyla en alakalÄ± metin parÃ§alarÄ±nÄ± **VektÃ¶r VeritabanÄ± (ChromaDB)** Ã¼zerinden bulur.
* **Google Gemini Entegrasyonu:** En gÃ¼ncel **Gemini 2.5 Flash** modelini kullanarak akÄ±cÄ± ve TÃ¼rkÃ§e cevaplar Ã¼retir.
* **Kaynak GÃ¶sterimi:** CevabÄ±n hangi sayfadan ve hangi parÃ§adan alÄ±ndÄ±ÄŸÄ±nÄ± ÅŸeffaf bir ÅŸekilde gÃ¶sterir.
* **Ayarlanabilir Parametreler:**
    * `Chunk Size`: Metin parÃ§alama boyutu.
    * `k DeÄŸeri`: Cevap iÃ§in kaÃ§ parÃ§a metin kullanÄ±lacaÄŸÄ±.
* **KullanÄ±cÄ± Dostu ArayÃ¼z:** Streamlit ile geliÅŸtirilmiÅŸ modern ve hÄ±zlÄ± arayÃ¼z.

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

* **Dil:** Python 3.10
* **ArayÃ¼z:** Streamlit
* **Orkestrasyon:** LangChain (v0.2 Stable)
* **LLM & Embedding:** Google Gemini API (`gemini-2.5-flash`)
* **VeritabanÄ±:** ChromaDB (Ephemeral/Bellek iÃ§i)

## ğŸ“¸ Ekran GÃ¶rÃ¼ntÃ¼leri

### 1. Soru Cevap ve Kaynak GÃ¶sterimi
KullanÄ±cÄ± "Mazeret sÄ±navÄ± hakkÄ± nedir?" diye sorduÄŸunda sistemin verdiÄŸi kaynaklÄ± cevap:

![Soru Cevap Ã–rneÄŸi](screenshots/1.hafta/ss1.png)

![Soru Cevap Ã–rneÄŸi](screenshots/1.hafta/ss3.png)

![Soru Cevap Ã–rneÄŸi](screenshots/1.hafta/ss2.png)

### 2. Ayarlar ve DokÃ¼man YÃ¼kleme
PDF yÃ¼kleme alanÄ± ve Chunk/k ayarlarÄ±:

![Ayarlar MenÃ¼sÃ¼](screenshots/1.hafta/ayarlar.png)

## âš™ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

Projeyi kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

1.  **Gereksinimleri YÃ¼kleyin:**
    ```bash
    pip install -r requirements.txt
    ```

2.  **API AnahtarÄ±nÄ± AyarlayÄ±n:**
    `app.py` dosyasÄ± iÃ§erisine Google AI Studio'dan aldÄ±ÄŸÄ±nÄ±z API anahtarÄ±nÄ± ekleyin.

3.  **UygulamayÄ± BaÅŸlatÄ±n:**
    Terminalde ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
    ```bash
    streamlit run app.py
    ```

## ğŸ§ª Test Edilen Senaryolar (1. Hafta)

* [x] PDF yÃ¼kleme ve metin parÃ§alama (Chunking).
* [x] VektÃ¶r veritabanÄ±na kayÄ±t.
* [x] "BaÄŸlamda yoksa uydurma" kuralÄ±nÄ±n uygulanmasÄ±.
* [x] CevaplarÄ±n madde madde listelenmesi.
* [x] CevabÄ±n dayandÄ±ÄŸÄ± kaynaklarÄ±n (Sayfa no) gÃ¶sterilmesi.

---


---
## ğŸ§  2. Hafta: GeliÅŸmiÅŸ RAG (MMR & Prompt Engineering)

Bu aÅŸamada sisteme "Ã§eÅŸitlilik" kazandÄ±rÄ±lmÄ±ÅŸ ve cevap kalitesi artÄ±rÄ±lmÄ±ÅŸtÄ±r.

### âœ¨ YapÄ±lan GeliÅŸtirmeler
1.  **MMR (Maximal Marginal Relevance) Entegrasyonu:**
    * Sadece en benzer kelimeleri deÄŸil, anlamsal olarak farklÄ± noktalarÄ± da taramasÄ± saÄŸlandÄ±.
    * *KanÄ±t:* "YÃ¶netmeliÄŸin amacÄ±" sorusunda Similarity yÃ¶ntemi sadece 2. ve 6. sayfaya bakarken, MMR yÃ¶ntemi 1., 6. ve 8. sayfalardan veri toplayarak daha kapsamlÄ± bir Ã¶zet Ã§Ä±kardÄ±.

2.  **GeliÅŸmiÅŸ Prompt TasarÄ±mÄ±:**
    * Modele *"Ã–nce 1 cÃ¼mlelik yÃ¶netici Ã¶zeti Ã§Ä±kar, sonra detaylarÄ± maddeleÅŸtir"* talimatÄ± verildi.
    * CevaplarÄ±n okunabilirliÄŸi ve profesyonelliÄŸi artÄ±rÄ±ldÄ±.

3.  **Dinamik Parametreler:**
    * ArayÃ¼z Ã¼zerinden `Similarity` vs `MMR` geÃ§iÅŸi yapabilme Ã¶zelliÄŸi eklendi.

### ğŸ“¸ KarÅŸÄ±laÅŸtÄ±rma Testleri

**Test 1: MMR FarkÄ±**
AynÄ± soruya MMR (Ã‡eÅŸitlilik) modunda verilen cevap ve kaynaklarÄ±n geniÅŸ daÄŸÄ±lÄ±mÄ±:
![MMR Ã–rneÄŸi](screenshots/2.hafta/ss4.png)

**Test 2: DÃ¼rÃ¼stlÃ¼k KontrolÃ¼ (Hallucination Check)**
Metinde tam listesi olmayan bir soru sorulduÄŸunda modelin "Bilmiyorum" deme yeteneÄŸi:
![Disiplin Sorusu](screenshots/2.hafta/ss1.png)



---
## ğŸ“š 3. Hafta: Ã‡ok KaynaklÄ± RAG (Multi-Source Retrieval)

Projenin final aÅŸamasÄ±nda sistem, birden fazla PDF dokÃ¼manÄ±nÄ± aynÄ± anda iÅŸleyip, sorulara bu belgeleri sentezleyerek cevap verecek hale getirilmiÅŸtir.

### âœ¨ Eklenen Ã–zellikler
1.  **Ã‡oklu Dosya YÃ¼kleme:**
    * `st.file_uploader` gÃ¼ncellenerek `accept_multiple_files=True` yapÄ±ldÄ±.
    * KullanÄ±cÄ± aynÄ± anda Lisans YÃ¶netmeliÄŸi ve LisansÃ¼stÃ¼ DanÄ±ÅŸmanlÄ±k YÃ¶nergesi gibi farklÄ± belgeleri yÃ¼kleyebilir.

2.  **Metadata TabanlÄ± Kaynak Takibi:**
    * Her metin parÃ§asÄ±na (chunk) `metadata["source"]` etiketi eklendi.
    * Bu sayede modelin hangi bilgiyi hangi dosyadan aldÄ±ÄŸÄ± takip edilebilir hale geldi.

3.  **Sentez Cevaplama:**
    * Model, farklÄ± dosyalardan gelen parÃ§alarÄ± birleÅŸtirerek bÃ¼tÃ¼nleÅŸik cevaplar Ã¼retir.

### ğŸ“¸ Test Sonucu (KanÄ±t)
AÅŸaÄŸÄ±daki ekran gÃ¶rÃ¼ntÃ¼sÃ¼nde gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere, sistem tek bir soru iÃ§in **iki farklÄ± PDF dosyasÄ±ndan** (Kaynak 4 farklÄ±, diÄŸerleri farklÄ±) parÃ§a getirmiÅŸ ve bunlarÄ± kullanmÄ±ÅŸtÄ±r:

![Ã‡oklu Kaynak KanÄ±tÄ±](screenshots/3.hafta/ss1.png)