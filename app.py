import streamlit as st
import os


MY_API_KEY = "AIzaSyDKqVM_cGh3ceLzd4V-t58QhgodRnZZ4Yc"


os.environ["GOOGLE_API_KEY"] = MY_API_KEY


from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate


st.set_page_config(page_title="FÄ±rat Ãœni AsistanÄ±", layout="wide")
st.title("1. Hafta: Mevzuat RAG ")


with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    uploaded_file = st.file_uploader("Bir PDF YÃ¼kle", type="pdf")

    st.markdown("---")
    chunk_size = st.slider("ParÃ§a Boyutu (Chunk Size)", 500, 2000, 1000)
    k_value = st.slider("KaÃ§ ParÃ§a Getirilsin? (k)", 1, 10, 3)


    if st.button("Sohbeti Temizle"):
        st.session_state.clear()
        st.rerun()



def process_pdf(file, chunk_s):

    with open("temp.pdf", "wb") as f:
        f.write(file.getbuffer())

    loader = PyPDFLoader("temp.pdf")
    pages = loader.load()

    # BÃ¶lme iÅŸlemi
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_s,
        chunk_overlap=100
    )
    docs = splitter.split_documents(pages)
    return docs


def get_vectorstore(docs):

    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    db = Chroma.from_documents(docs, embeddings)
    return db



if uploaded_file:


    if "db" not in st.session_state:
        with st.spinner("PDF taranÄ±yor ve vektÃ¶rlere Ã§evriliyor..."):
            try:
                docs = process_pdf(uploaded_file, chunk_size)
                st.session_state.db = get_vectorstore(docs)
                st.success(f"Ä°ÅŸlem BaÅŸarÄ±lÄ±! Belge {len(docs)} parÃ§aya ayrÄ±ldÄ±.")
            except Exception as e:
                st.error(f"Bir hata oluÅŸtu: {e}")


    question = st.text_input("Sorunuzu buraya yazÄ±n:", placeholder="Ã–rn: Mazeret sÄ±navÄ± hakkÄ± nedir?")

    if question and "db" in st.session_state:

        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)


        prompt_template = """
        AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak soruyu cevapla.
        EÄŸer cevap metinde yoksa "Bilgim yok" de, uydurma.
        CevabÄ± sade ve anlaÅŸÄ±lÄ±r maddeler halinde yaz.

        BaÄŸlam: {context}
        Soru: {question}

        Cevap:
        """
        PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

        # Zinciri Kur
        qa_chain = RetrievalQA.from_chain_type(
            llm,
            retriever=st.session_state.db.as_retriever(search_kwargs={"k": k_value}),
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )

        # CevabÄ± Al
        with st.spinner("Yapay zeka dÃ¼ÅŸÃ¼nÃ¼yor..."):
            res = qa_chain.invoke({"query": question})

            st.markdown("### ğŸ¤– Cevap:")
            st.write(res["result"])


            st.markdown("---")
            st.caption("ğŸ” KullanÄ±lan Kaynak ParÃ§alar:")
            for i, doc in enumerate(res["source_documents"]):
                with st.expander(f"Kaynak {i + 1} (Sayfa {doc.metadata.get('page', 0) + 1})"):
                    st.info(doc.page_content)

elif not uploaded_file:
    st.info("Sol taraftan bir PDF yÃ¼kleyerek baÅŸlayÄ±n.")